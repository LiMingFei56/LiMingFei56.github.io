## 1 CPU 功能和组成
	CPU叫做中央处理器(Central Processing Unit),做成单片集成电路的ＣＰＵ通又
	被称为微处理器(MicroProcessor).

### 1.1 指令的分类
	从计算机组成的层次结构来说,计算机的指令分为微指令、机器指令和宏指令三类.
	微指令是微程序级的命令,属于硬件；宏指令是由若干条机器指令组成的软件指令
	,属于软件；机器指令,也就是我们通常所说的指令,介于微指令与宏指令之间
	,每条指令可完成一个独立的算术运算或逻辑运算.

	指令系统(CISC OR RISC)发展到现在,经过相互的借鉴和优化,在
	功耗、性能上已经很接近了.

#### 1.1.1 复杂指令系统计算机(Complex Instruction Set Computer)
	使用冯诺伊曼结构
	优点:
		1. 指令功能丰富,寻址方式灵活
		2. 适合通用计算机
	缺点:
		1. 硬件复杂,造价高
		2. 指令长度不定,效难控制指定周期

#### 1.1.2 精简指令系统计算机(Reduced Instruction Set Computer)
	使用哈佛结构
	优点:
		1. 硬件:指令简单,常用的指令只有复杂指令20%,其他的功能也可以用这个20%
		   指令组合而成.这样结构简单,硬件实现简单,适合单片机上使用.
		2. 指令长度固定
	缺点:
		1. 指令单一,复杂操作需要调用多个指令来实现.

### 1.2 指令系统的性能要求
		1. 完备性,需要提供编写程序时必不可少的指令,其他的指定可以用基础指令
		   组合完成,或用硬件来实现.
		2. 有效性,提供的指定要高效的运行,表现在存储空间小,执行速度快.
		3. 规整性,规整性是指指令系统的对称性、匀齐性、指令格式和数据格式的一致性
		   .表现在对寄存器和存储器的对称,操作不同数据类型的匀齐,指令长度和数据长
		   度处理的一致性.
		4. 兼容性,计算机之间具有相同的基本结构、数据表示和共同的基本指令集合.

### 1.3 CPU的基本功能
		1. 程序控制,控制程序顺序执行.
		2. 操作控制,控制指令进行操作.
		3. 时间控件,对各种操作实施定时控制.
		4. 数据加工,对数据进行算术运算,逻辑运算.

### 1.4 CPU基本组成
		1. 控制器,通常由程序计数器(PC)、指令寄存器(IR)、指令译码器(ID)、时序发生
		   器和操作控制器组成.
		2. 运算器(ALU),由算术逻辑单元(ALU)、累加寄存器(AC)、数据寄存器(DR)和程序
		   状态字寄存器(PSW)组成.
		3. 数据寄存器(DR),主要作为CPU和主存、外设之间信息传输的中转站.
		4. 指令寄存器(IR),保存当前正在执行的一条指令.
		5. 程序计数器(PC),指出下一条指令在主存储器中的单元地址.
		6. 地址寄存器(AR),保存CPU当前所访问的主存单元的地址.
		7. 累加寄存器(AC),当运算器的算术逻辑单元(ALU)执行算术或逻辑运算时,为ALU
		   提供一个工作区,可以为ALU暂时保存一个操作数或运算结果.
		8. 程序状态字寄存器(PSW),用来表征当前运算的状态及程序的工作方式.
		9. 时序信号发生器,固定频率发出信号,对各种控制信号实施时间上的严格控制.

### 1.5 CPU指令的执行过程
		1. 取指令(IF),将一条指令从主存中取到指令寄存器的过程.现代CPU为了提高性能
		   ,会有指令缓冲区,会把当前指令后面多条指令从内存中读到缓冲区,大大加快取
		   指令的速度.但是当程序跳转时(比如IF语句),缓冲区的指令就失效了,要在跳转
		   后重新取得内存中的指令,转移分为转移不成功和转移成功两种,可以使用猜测
		   时,大多数机器会猜测不成功转移,如果猜对的机率高,那么会大大的提高性能.

		2. 指令译码(ID),按照预定的指令格式,对取回的指令进行拆分和解释,识别和区分
		   出不同的指令类别及各种获取操作数的方法.
		3. 执行指令(EX),完成指令所规定的各种操作,具体实现指令的功能.
		4. 访存取数(MEM),根据指令地址码,得到操作数在主存中的地址,并从主存中读取
		   该操作数用
		   于运算.
		5. 结果写回(WB),把执行指令阶段的运行结果数据“写回”到某种存储形式.

### 1.6 CPU指令周期
		1. 指令周期,CPU取出一条指令并执行该指令所需的时间称为指令周期,指令周期
		   的长短与指令的复杂程度有关.
		2. CPU周期(机器周期),由于CPU内部的操作速度较快,而CPU访问一次主存所花的时
		   间较长,因此通常用从主存读取一条指令的最短时间来规定CPU周期.
		3. 时钟周期,一个CPU周期包含有若干个时钟周期,时钟周期是处理操作的最基本时
		   间单位,由机器的主频决定.
		4. 取出和执行任何一条指令所需的最短时间为两个CPU周期,指令执行需要的时间
		   与指令复杂度有关,最少需要一个CPU周期.

### 1.7 时序发生器

#### 1.7.1 时序信号
		计算机运行时为了协调各部件工作,需要严格遵守时间规定,时序信号就是用时序发
		生器来产生的.
		
		指令和数据都是存储在内存中的,CPU是以工作阶段来区分指令和数据,在取指令阶
		段取出的内容是发往指令寄存器,在执行阶段取出的数据是发往运算器.

#### 1.7.2 时序发生器
		CPU中的时序信号发生器,其功能是用逻辑电路来发出时序信号,实现时序控制,使计
		算机可以准确、迅速、有条不紊地工作.

		操作控制器利用时序信号和时序信号间隔时间,来实现微操作定时控制,让各部件有
		条理,有节奏的工作.

### 1.8 控制方式
		为了使机器能够正确执行指令,控制器必须能够按正确的时序产生操作控制信号.控
		制不同操作序列的时序信号的方法,称为控制器的控制方式.控制方式通常分为三种
		:同步控制方式,异步控制方式,联合控制方式,其实质反映了时序信号的定时方式.

#### 1.8.1 同步控制方式
		同步控制方式是指操作序列中每一步操作的执行,都由确定的具有基准时标的时序
		信号来控制,其特点是系统有一个统一的时钟,所有的控制信号均来自这个统一的时
		钟信号.

#### 1.8.2 异步控制方式
		异步控制方式是一种按每条指令,每个操作的实际需要而占用时间的控制方式,不同
		指令所占用的时间完全根据需要来决定.

#### 1.8.3 联合控制方式
		联合控制方式的设计思想是:在功能部件内部采用同步控制方式,而在功能部件之间
		采用异步控制方式,并且在硬件实现允许的情况下,尽可能多地采用异步控制方式

## 2 多核CPU并行计算
		单核CPU时为了并行计算,是把CPU工作时间分为一个个片段,每一个片段切换不同的
		程序运行,片段的时间很短,所以给用户的感觉是多个程序在并行运行.
		
		随着科技的发展,在一个CPU中可以集成多个核心,每个核心有自己的寄存器和高速
		缓存,共享低级缓存和内存,可以实现真正意义上的并行.

### 2.1 Flynn分类
		1. 单指令流单数据流（Single Instruction stream Single Data stream -- SIS
		   D）
		2. 单指令流多数据流（Single Instruction stream Multiple Data stream -- S
		   IMD）
		3. 多指令流单数据流（Multiple Instruction stream Single Data stream -- M
		   ISD）
		4. 多指令流多数据流（Multiple Instruction stream Multiple Data stream --
		   MISD）
		
		其中指令流（instruction stream）指机器执行的指令序列；数据流（data strea
		m）指指令流调用的数据序列,包括输入数据和中间结果.


### 2.2 超级计算机

#### 2.2.1 分布式存储器的SIMD处理机
		含有多个同样结构的处理单元（PE）,通过寻径网络以一定方式互相连接.每个PE有
		各自的本地存储器（LM）.在阵列控制部件的统一指挥下,实现并行操作.程序和数
		据通过主机装入控制存储器.由于通过控制部件的是单指令流,所以指令的执行顺序
		还是和单处理机一样,基本上是串行处理.指令送到控制部件进行译码.如果是标量
		指令,则直接由标量处理机执行.如果是向量指令,则阵列控制部件通过广播总线将
		它广播到所有PE并行执行.划分后的数据集合通过向量数据总线分布到所有PE的本
		地存储器LM.PE通过数据寻径网络互连.数据寻径网络执行PE间的通信.控制部件通
		过执行程序来控制数据寻径网络.PE的同步由控制部件的硬件实现.也就是说,所有
		PE在同一个周期执行同一条指令.但是可以用屏蔽逻辑来决定任何一个PE在给定的
		指令周期执行或不执行指令.

#### 2.2.2 向量超级计算机（共享式存储器SIMD）
		这是集中设置存储器的一种方案.共享的多个并行存储器通过对准网络与各处理单
		元PE相连.存储模块的数目等于或略大于处理单元的数目.为了减少存储器访问冲突
		,存储器模块之间必须合理分配数据.通过灵活高速的对准网络,使存储器与处理单
		元之间的数据传送在大多数向量运算中都能以存储器的最高频率进行.这种共享存
		储器模型在处理单元数目不太大的情况下是很理想的.例如美国宝来公司的BSP计算
		机采用了这种结构.16个PE通过一个16×17的对准网络访问17个共享存储器模块.存
		储器模块数与PE数互质可以实现无冲突并行访问存储器.

#### 2.2.3 对称多处理器（SMP）
		SMP是指在一个计算机上汇集了一组处理器,各处理器之间共享内存子系统以及总线
		结构.它是相对非对称多处理技术而言的、应用十分广泛的并行技术.在这种架构中
		,一台电脑不再由单个CPU组成,而同时由多个处理器运行操作系统的单一复本,并共
		享内存和一台计算机的其他资源.虽然同时使用多个CPU,但是从管理的角度来看,它
		们的表现就像一台单机一样.系统将任务队列对称地分布于多个CPU之上,从而极大
		地提高了整个系统的数据处理能力.所有的处理器都可以平等地访问内存、I/O和外
		部中断.在对称多处理系统中,系统资源被系统中所有CPU共享,工作负载能够均匀地
		分配到所有可用处理器之上.

#### 2.2.4 并行向量处理机（PVP）
		在并行向量处理机中有少量专门定制的向量处理器.每个向量处理器有很高的处理
		能力.并行向量处理机通过向量处理和多个向量处理器并行处理两条途径来提高处
		理能力.并行向量处理机通常使用定制的高带宽网络将向量处理器连向共享存储器
		模块.存储器可以以很高的速度向处理器提供数据.这种机器通常不使用高速缓存,
		而是使用大量的向量寄存器和指令缓冲器.

#### 2.2.5 集群计算机
		集群计算机是随着微处理器和网络技术的进步而逐渐发展起来的,它主要用来解决
		大型计算问题.集群计算机是一种并行或分布式处理系统,由很多连接在一起的独立
		计算机组成,像一个单独集成的计算机资源一样协同工作.计算机节点可以是一个单
		处理器或多处理器的系统,拥有内存、IO设备和操作系统.一个集群一般是指连接在
		一起的两个或多个计算机（节点）.节点可以是在一起的,也可以是物理上分散而通
		过网络连结在一起的.一个连接在一起的计算机集群对于用户和应用程序来说像一
		个单一的系统,这样的系统可以提供一种价格合理的且可获得所需性能和快速而可
		靠的服务的解决方案,而在以往只能通过更昂贵的专用共享内存系统来达到.

### 2.3 指令级并行

#### 2.3.1 乱序执行(out-of-orderexecution)和指令重排
		顺序执行复杂指令,不可避免的陷入等待,这样很浪费CPU的资源,而且当前几条预加
		载的几条指令间没有依赖结果,那么可以消耗少的指令可以先执行.代码顺序并不是
		真正的执行顺序,只要有空间提高性能,CPU和编译器可以进行各种优化.缓存和主存
		的读取会利用load,store和write-combining缓冲区来缓冲和重排.

		乱序执行种类
		写写(store store):a=1;b=2-------------> b=2;a=1;
		写读(store load ):a=1;load(b); ------------> load(b);a=1;
		读读(load  load ):load(a);load(b);  -----------> load(b);load(a);
		读写(load  store):load(a);b=2; ------------> b=2;load(a);

#### 2.3.2 内存可见性
		多核CPU内,每个核心有自己的寄存器,甚至1级缓存,2级缓存.对每个指令执行的结
		果,为了效率考虑不一定会写回到3级存疑或者内存里,所以CPU0执行的结果对CPU1
		是不可以见的.

		CPU内有6个执行单元,可以组合进行算术,逻辑,寻址等操作,可以并行执行,这样在
		其他CPU核心的角度看,就产生了程序顺序执行的不确定性.

		在多核CPU编程里,为了让其他核心可以立即对处理结果可见,需要在产生新数据时
		有消息协议来确保所有核心的缓存和内存内的共享数据同步并保持一致.这种使内
		存数据对所有CPU核心可见的技术叫内存屏障或内存栅栏.

		内存屏障一般实现2个功能:
			1. 确保从另一个CPU来看屏障两边的所有指令都是正确的程序顺序.
			2. 确保内存可见性,同步新数据到所以CPU缓存上.

		内存屏障指令:
			1. Store屏障,是x86的”sfence“指令,强制所有在store屏障指令之前的store
			   指令,都在该store屏障指令执行之前被执行,并把store缓冲区的数据都刷
			   到CPU缓存.

			2. Load屏障,是x86上的”ifence“指令,强制所有在load屏障指令之后的load指
			   令,都在该load屏障指令执行之后被执行,并且一直等到load缓冲区被该CPU
			   读完才能执行之后的load指令.

			3. Full屏障,是x86上的”mfence“指令,复合了load和save屏障的功能.

			Lock是一个指令前缀,会使后同跟随的指令变成原子指令.暂时的锁一下总线,
			指令执行完,总线就解锁了.

			mlock函数族为操作系统提供,用来锁定内存块

			LOCK的消耗比mlock大,所以锁的垃度越小越好.

		内存屏障的性能影响:
			内存屏障阻碍了CPU的指令优化,LOCK指令更是对总线加锁,这样级大的影响性
			能.最好把要解决的问题细化,模块化,谨慎的使用内存屏障和LOCK指令.
				

#### 2.3.3 原子操作
		原子操作是不可分割的,在执行完毕不会被任何其它任务或事件中断.在单处理器系
		统(UniProcessor)中,能够在单条指令中完成的操作都可以认为是"原子操作",因为
		中断只能发生于指令之间.这也是某些CPU指令系统中引入了test_and_set、test_
		and_clear等指令用于临界资源互斥的原因.在对称多处理器(Symmetric Multi-Pro
		cessor)结构中就不同了,由于系统中有多个处理器在独立地运行,即使能在单条指
		令中完成的操作也有可能受到干扰.在x86平台上,CPU提供了在指令执行期间对总线
		加锁的手段.CPU芯片上有一条引线#HLOCK pin,如果汇编语言的程序中在一条指令
		前面加上前缀"LOCK",经过汇编以后的机器代码就使CPU在执行这条指令的时候把#H
		LOCK pin的电位拉低,持续到这条指令结束时放开,从而把总线锁住,这样同一总线
		上别的CPU就暂时不能通过总线访问内存了,保证了这条指令在多处理器环境中的原
		子性.
